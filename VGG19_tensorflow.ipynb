{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#Train IELM and evaluating training accuracy\n",
        "no_classes = 8\n",
        "error = 0.1\n",
        "loss_function = \"binary_cross_entropy\" #\"mean_squared_error\"  #It can be mean_absolute_error also\n",
        "activation_function = \"tanh\"\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set the GPU memory growth option\n",
        "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
        "print(physical_devices)\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loading_data(train_path,test_path):\n",
        "\n",
        "    # Define the data transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # Resize images to (224, 224)\n",
        "        transforms.ToTensor(),  # Convert images to tensors\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images\n",
        "    ])\n",
        "\n",
        "    \n",
        "\n",
        "    train_dataset = ImageFolder(train_path, transform=transform)\n",
        "    traindata_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "\n",
        "    test_dataset = ImageFolder(test_path, transform=transform)\n",
        "    testdata_loader = DataLoader(test_dataset, batch_size=10, shuffle=True)\n",
        "    return traindata_loader,testdata_loader\n",
        "\n",
        "def load_model():\n",
        "    #loading of model\n",
        "    device=torch.device(\"cuda\")  \n",
        "    \n",
        "    vgg_model = models.vgg19(weights=models.VGG19_Weights.DEFAULT)\n",
        "    vgg_model = torch.nn.Sequential(*list(vgg_model.features.children()))\n",
        "    vgg_model=vgg_model.to(device)\n",
        "    vgg_model.eval()\n",
        "    return vgg_model\n",
        "#training features extraction\n",
        "def training_feature_extraction(device, traindata_loader,vgg_model):\n",
        "\n",
        "    x_training_features = []\n",
        "    y_train_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in traindata_loader:        \n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # Extract features using VGG16\n",
        "            with torch.no_grad():\n",
        "                features = vgg_model(images)   \n",
        "            \n",
        "            x_training_features.append(features)\n",
        "            y_train_labels.append(labels)\n",
        "    x_training_features = torch.cat(x_training_features, dim=0)\n",
        "    y_train_labels = torch.cat(y_train_labels, dim=0)\n",
        "\n",
        "    x_training_features.to(device)\n",
        "    y_train_labels.to(device)\n",
        "    return x_training_features,y_train_labels\n",
        "\n",
        "def testing_feature_extratcion(device,testdata_loader,vgg_model):\n",
        "    x_testing_features = []\n",
        "    y_testing_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testdata_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # Extract features using VGG19\n",
        "            with torch.no_grad():\n",
        "                features = vgg_model(images) \n",
        "            x_testing_features.append(vgg_model(images))\n",
        "            y_testing_labels.append(labels)\n",
        "    x_testing_features = torch.cat(x_testing_features, dim=0)\n",
        "    y_testing_labels = torch.cat(y_testing_labels, dim=0)\n",
        "\n",
        "    x_testing_features.to(device)\n",
        "    y_testing_labels.to(device)\n",
        "    return x_testing_features,y_testing_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "IELM Constructor class\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "class I_ELM():\n",
        "    \"\"\" Constructor to initialize node\"\"\"\n",
        "    def __init__(self, no_input_nodes, max_no_hidden_nodes, no_output_nodes,\n",
        "        activation_function='sigmoid', loss_function='mean_squared_error'):\n",
        "        device=torch.device(\"cuda\") \n",
        "        \n",
        "        self.no_input_nodes = no_input_nodes\n",
        "        self.no_hidden_nodes = 1\n",
        "        self.no_output_nodes = no_output_nodes\n",
        "\n",
        "        self.beta = torch.FloatTensor(self.no_hidden_nodes, self.no_output_nodes).uniform_(-1., 1.)\n",
        "        self.beta=self.beta.to(device)\n",
        "        \n",
        "        # initialize weights between Input Layer and hidden layer\n",
        "        self.alpha=torch.FloatTensor(self.no_input_nodes, self.no_hidden_nodes).uniform_(-1.,1.)\n",
        "        self.alpha=self.alpha.to(device)\n",
        "        \n",
        "        # Initialize Biases\n",
        "        self.bias =torch.zeros(size=(self.no_hidden_nodes,))\n",
        "        self.bias=self.bias.to(device)\n",
        "        # set an activation function\n",
        "        self.activation_function = activation_function\n",
        "       \n",
        "        # set a loss function\n",
        "        self.loss_function = loss_function\n",
        "    \n",
        "    def mean_squared_error(self,Y_True, Y_Pred):\n",
        "        return 0.5 * torch.mean((Y_True - Y_Pred)**2)\n",
        "\n",
        "    def mean_absolute_error(self, Y_True, Y_Pred):\n",
        "        return torch.mean(torch.abs(Y_True - Y_Pred))\n",
        "    \n",
        "    def sigmoid(self, x):\n",
        "        return 1. /(1.+ torch.exp(-x))\n",
        "    \n",
        "    def predict(self, X):\n",
        "        return torch.tensor(self(X), dtype=torch.float32)\n",
        "    \n",
        "    def __call__(self, X):\n",
        "        h = torch.sigmoid(torch.matmul(X,self.alpha) + self.bias)\n",
        "        return torch.matmul(h,self.beta)\n",
        "    \n",
        "    def binary_cross_entropy(self,Y_true, Y_pred):\n",
        "        lss=[]\n",
        "        Y_pred = torch.clamp(Y_pred, min=1e-7, max=1.0 - 1e-7)\n",
        "        loss_calculated=- (Y_true * torch.log(Y_pred) + (1 - Y_true) * torch.log(1 - Y_pred))\n",
        "        '''loss_calculated_max=torch.argmax(loss_calculated, axis=-1)\n",
        "        loss_calculated_max=loss_calculated_max.cpu()\n",
        "        \n",
        "        for i in range(len(loss_calculated_max)):\n",
        "            l1=loss_calculated_max[i]\n",
        "            lss.append(l1)\n",
        "        #print(lss)\n",
        "        plt.plot(range(1, Lmax), lss)\n",
        "        plt.xlabel('Hidden Layer Neurons')\n",
        "        plt.ylabel('Training Loss')\n",
        "        #plt.title('BCE Loss Over Epochs')\n",
        "        plt.show()\n",
        "        '''\n",
        "        loss=torch.mean(loss_calculated)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def plot_confusion(self,Y_true, Y_pred):\n",
        "         \n",
        "        # Calculate the confusion matrix \n",
        "        confusion = confusion_matrix(Y_true, Y_pred)\n",
        "        \n",
        "        # Extract values from the confusion matrix\n",
        "        TP = confusion[1, 1]\n",
        "        FP = confusion[0, 1]\n",
        "        TN = confusion[0, 0]\n",
        "        FN = confusion[1, 0]\n",
        "        TPR= TP/(TP+FN)\n",
        "        FPR=FP/(FP+TN)\n",
        "        X=[0,FPR,1]\n",
        "        Y=[0,TPR,1]\n",
        "        AUCSCORE =np.trapz(Y,X)\n",
        "\n",
        "        # Calculate precision, recall, and F1-score\n",
        "        precision, recall, f1_score, _ = precision_recall_fscore_support(Y_true,Y_pred, average='macro')\n",
        "\n",
        "        print(\"precision=\",precision,\"recall=\",recall,\"f1-score=\",f1_score,\"auc-score=\",AUCSCORE)\n",
        "\n",
        "        Sensitivity =TP/(TP+FN)\n",
        "        Specificity =TN/(TN+FP)\n",
        "        fpr = 1-Specificity\n",
        "        print(\"sensitivity=\",Sensitivity,\"specificity=\",Specificity,\"fpr=\",fpr)\n",
        "        \n",
        "        import pandas as pd\n",
        "\n",
        "        data = {'Column1':[precision,recall,f1_score,AUCSCORE,Sensitivity,Specificity,fpr]}\n",
        "        df_matric = pd.DataFrame(data=data)\n",
        "        df_matric.index  = ['Precision', 'recall', 'f1-score','Accuracy Score','sensitivity','specificity','fpr']\n",
        "        print(df_matric)\n",
        "\n",
        "        \n",
        "        # Get the number of classes\n",
        "        num_classes = len(np.unique(Y_true))\n",
        "\n",
        "        # Create a figure and axis\n",
        "        # Create a figure and axis\n",
        "        fig, ax = plt.subplots(figsize=(4,4))\n",
        "        cmlabels=['Apple','Corn','Grape','Potato','Rice','Tea','Tomato','Wheat']\n",
        "        # Plot the confusion matrix using a heatmap\n",
        "        sns.heatmap(confusion, annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False, ax=ax,xticklabels=cmlabels,yticklabels=cmlabels)\n",
        "\n",
        "        # Set axis labels and title\n",
        "        ax.set_xlabel(\"Predicted labels\")\n",
        "        ax.set_ylabel(\"Actual labels\")\n",
        "        title=\"CM For VGG19 Model 02 \"\n",
        "        ax.set_title(\"\")\n",
        "        plt.savefig(title+'confusion_matrix.png')\n",
        "        # Show the plot\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    def evaluate(self, X, Y_true, metrics):\n",
        "        Y_pred =self.predict(X)\n",
        "        #Y_true = Y_true\n",
        "        \n",
        "        ret = []\n",
        "        \n",
        "        Y_pred=torch.tensor(Y_pred,dtype=torch.float32)\n",
        "\n",
        "\n",
        "        for m in metrics:\n",
        "            if m == 'loss':\n",
        "                loss=[]\n",
        "                loss = self.binary_cross_entropy(Y_true, Y_pred)\n",
        "                ret.append(loss)                \n",
        "            elif m == 'accuracy':\n",
        "                Y_pred_argmax = torch.argmax(Y_pred, axis=-1)\n",
        "                Y_true_argmax = torch.argmax(Y_true, axis=-1)\n",
        "                acc = torch.sum(Y_pred_argmax == Y_true_argmax) / len(Y_true)\n",
        "                #plotting of confusion matrix\n",
        "\n",
        "                # Get predicted probabilities for positive class\n",
        "                Y_true_argmax=Y_true_argmax.cpu()\n",
        "                Y_pred_argmax=Y_pred_argmax.cpu()\n",
        "                #self.plot_confusion(Y_true_argmax, Y_pred_argmax)\n",
        "                ret.append(acc)\n",
        "            else:\n",
        "                raise ValueError('an unknown evaluation indicator \\'%s\\'.' % m)\n",
        "        if len(ret) == 1:\n",
        "            print(ret)\n",
        "            ret = ret\n",
        "        elif len(ret) == 0:\n",
        "            ret = None\n",
        "        return ret\n",
        "\n",
        "    def fit(self, X, Y_true,Lmax,error,activation):\n",
        "        device=torch.device(\"cuda\")\n",
        "        with torch.no_grad():\n",
        "            self.beta=torch.FloatTensor(np.random.uniform(-1.,1.,size=(1, self.no_output_nodes)))\n",
        "            self.alpha = torch.FloatTensor(self.no_input_nodes, 1).uniform_(-1,1)\n",
        "            #print(self.beta.shape, self.alpha.shape,X.shape)\n",
        "            \n",
        "            self.alpha=self.alpha.to(device)\n",
        "            self.beta=self.beta.to(device)\n",
        "            if(activation=='s'):\n",
        "                H = torch.sigmoid(torch.matmul(X, self.alpha))\n",
        "            elif(activation=='t'):\n",
        "                H = torch.tanh(torch.matmul(X, self.alpha))  \n",
        "            elif(activation=='r'):\n",
        "                H = torch.relu(torch.matmul(X, self.alpha))\n",
        "            \n",
        "            # Compute a pseudoinverse of H\n",
        "            H_pinv = torch.pinverse(H)\n",
        "\n",
        "            # Update beta\n",
        "            self.beta = torch.matmul(H_pinv, Y_true.float())\n",
        "            \n",
        "            for i in range(2, Lmax):\n",
        "                beta_random = torch.FloatTensor(np.random.uniform(-1.,1.,size=(1, self.no_output_nodes)))\n",
        "                alpha_random = torch.FloatTensor(self.no_input_nodes, 1).uniform_(-1,1)\n",
        "                \n",
        "                beta_random=beta_random.to(device)\n",
        "                alpha_random=alpha_random.to(device)\n",
        "                \n",
        "                self.alpha=torch.cat((self.alpha,alpha_random),dim=1)                          \n",
        "                self.beta =torch.cat((self.beta,beta_random),dim=0)\n",
        "\n",
        "                if(activation=='s'):\n",
        "                    H = torch.sigmoid(torch.matmul(X, self.alpha))\n",
        "                elif(activation=='t'):\n",
        "                    H = torch.tanh(torch.matmul(X, self.alpha))  \n",
        "                elif(activation=='r'):\n",
        "                    H = torch.relu(torch.matmul(X, self.alpha))\n",
        "                \n",
        "                H_pinv = torch.pinverse(H)\n",
        "                self.beta = torch.matmul(H_pinv, Y_true) \n",
        "\n",
        "from  keras.utils import np_utils\n",
        "def train_features_conversion(x_training_features,y_train_labels):\n",
        "\n",
        "    # Convert the extracted features to numpy arrays\n",
        "\n",
        "    device=torch.device(\"cuda\")\n",
        "    x_training_features_np = x_training_features.detach().cpu().numpy()  \n",
        "    flattened_features_train = x_training_features_np.reshape(x_training_features_np.shape[0], -1)\n",
        "    train_features_tensor = torch.tensor(flattened_features_train, dtype=torch.float32).to(device)\n",
        "    \n",
        "    y_train_array= y_train_labels.cpu().detach().numpy()\n",
        "    y_train_array_encoded = np_utils.to_categorical(y_train_array,no_classes)\n",
        "    y_train_labels_encoded=torch.tensor(y_train_array_encoded,dtype=torch.float32)\n",
        "    y_train_labels_encoded=y_train_labels_encoded.to(device)    \n",
        "    return train_features_tensor,y_train_labels_encoded\n",
        "\n",
        "def test_features_conversion(x_testing_features,y_testing_labels):\n",
        "    # Convert the extracted features to numpy arrays\n",
        "    device=torch.device(\"cuda\")\n",
        "    x_testing_features_np = x_testing_features.detach().cpu().numpy()\n",
        "    \n",
        "    flattened_features_test = x_testing_features_np.reshape(x_testing_features_np.shape[0], -1)\n",
        "    test_features_tensor = torch.tensor(flattened_features_test,dtype=torch.float32).to(device)\n",
        "    \n",
        "    y_test_array= y_testing_labels.cpu().detach().numpy()\n",
        "    y_test_array_encoded = np_utils.to_categorical(y_test_array,no_classes)\n",
        "    y_test_labels_encoded=torch.tensor(y_test_array_encoded,dtype=torch.float32)\n",
        "    y_test_labels_encoded=y_test_labels_encoded.to(device)\n",
        "    return test_features_tensor, y_test_labels_encoded\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device=torch.device(\"cuda\") \n",
        "train_path=\"D:/Smart_Farming_Capstone_Project_G201/Model02/Dataset/Type_of_plant/Train/\"\n",
        "test_path=\"D:/Smart_Farming_Capstone_Project_G201/Model02/Dataset/Type_of_plant/Test/\"\n",
        "traindata_loader,testdata_loader=loading_data(train_path,test_path)\n",
        "model=load_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_training_features,y_train_labels=training_feature_extraction(device,traindata_loader,model)\n",
        "train_features_tensor,y_train_labels_encoded=train_features_conversion(x_training_features,y_train_labels)\n",
        "torch.save(train_features_tensor,\"D:/Smart_Farming_Capstone_Project_G201/Model02/Feautres_Extraction/VGG19/Train/train_featuresVGG19.pth\")\n",
        "torch.save(y_train_labels_encoded,\"D:/Smart_Farming_Capstone_Project_G201/Model02/Feautres_Extraction/VGG19/Train/train_labelsVGG19.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_testing_features,y_testing_labels=testing_feature_extratcion(device,testdata_loader,model)\n",
        "test_features_tensor, y_test_labels_encoded=test_features_conversion(x_testing_features,y_testing_labels)\n",
        "torch.save(test_features_tensor,\"D:/Smart_Farming_Capstone_Project_G201/Model02/Feautres_Extraction/VGG19/Test/testing_featuresVGG19.pth\")\n",
        "torch.save(y_test_labels_encoded,\"D:/Smart_Farming_Capstone_Project_G201/Model02/Feautres_Extraction/VGG19/Test/testing_labelsVGG19.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def i_elmTraining(features_train,y_train,activation):\n",
        "  # ===============================\n",
        "  # Instantiate ELM object\n",
        "  # ===============================\n",
        "  input=features_train.size(1)\n",
        "  ielm_model = I_ELM(\n",
        "      no_input_nodes=input,\n",
        "      max_no_hidden_nodes=Lmax,\n",
        "      no_output_nodes=no_classes,\n",
        "      loss_function=loss_function,\n",
        "      activation_function=activation_function,    \n",
        "  )\n",
        "\n",
        "  i = time.time()  \n",
        "  ielm_model.fit(features_train,y_train,Lmax,error,activation)\n",
        "  final = time.time()\n",
        "\n",
        "  training_loss, training_acc = ielm_model.evaluate(features_train, y_train, metrics=['loss','accuracy'])\n",
        "  \n",
        "  print('Training Loss in mean square error: %f' % training_loss) # loss value\n",
        "  print('Training Accuracy: %f' % training_acc)# accuracy\n",
        "  print('Total Time require for Training %f Seconds'% (final-i))\n",
        "\n",
        "  return ielm_model\n",
        "def i_elmTesting(ielm_model,features_test,y_test):\n",
        "  \n",
        "  i = time.time()\n",
        "  test_loss, test_acc = ielm_model.evaluate(features_test, y_test, metrics=['loss', 'accuracy'])\n",
        "  final = time.time()\n",
        "  \n",
        "  print('Testing Loss in mean square error: %f ' % test_loss,\"\\n\")\n",
        "  print('Testing Accuracy: %f' % test_acc)\n",
        "  time_taken=(final-i)/features_test.shape[0]\n",
        "  print('The total testing time is ',(final-i))\n",
        "  print('Total Time require for Testing one image is ' ,time_taken ,'seconds')\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_training_features=torch.load(\"D:/Smart_Farming_Capstone_Project_G201/Model02/Feautres_Extraction/VGG19/Train/train_featuresVGG19.pth\")\n",
        "y_train_labels=torch.load(\"D:/Smart_Farming_Capstone_Project_G201/Model02/Feautres_Extraction/VGG19/Train/train_labelsVGG19.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "x_testing_features=torch.load(\"D:/Smart_Farming_Capstone_Project_G201/Model02/Feautres_Extraction/VGG19/Test/testing_featuresVGG19.pth\")\n",
        "y_testing_labels=torch.load(\"D:/Smart_Farming_Capstone_Project_G201/Model02/Feautres_Extraction/VGG19/Test/testing_labelsVGG19.pth\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Dr. Rajendra Ku Roul\\AppData\\Local\\Temp\\ipykernel_13544\\2997670534.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(self(X), dtype=torch.float32)\n",
            "C:\\Users\\Dr. Rajendra Ku Roul\\AppData\\Local\\Temp\\ipykernel_13544\\2997670534.py:131: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Y_pred=torch.tensor(Y_pred,dtype=torch.float32)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "no of neuron= 0 Testing Accuracy: 0.125444\n",
            "no of neuron= 1 Testing Accuracy: 0.123000\n",
            "no of neuron= 2 Testing Accuracy: 0.126667\n",
            "no of neuron= 3 Testing Accuracy: 0.178111\n",
            "no of neuron= 4 Testing Accuracy: 0.197111\n",
            "no of neuron= 5 Testing Accuracy: 0.262000\n",
            "no of neuron= 6 Testing Accuracy: 0.241444\n",
            "no of neuron= 7 Testing Accuracy: 0.243889\n",
            "no of neuron= 8 Testing Accuracy: 0.297444\n",
            "no of neuron= 9 Testing Accuracy: 0.312333\n",
            "no of neuron= 10 Testing Accuracy: 0.300333\n",
            "no of neuron= 11 Testing Accuracy: 0.339889\n",
            "no of neuron= 12 Testing Accuracy: 0.363111\n",
            "no of neuron= 13 Testing Accuracy: 0.361667\n",
            "no of neuron= 14 Testing Accuracy: 0.364333\n",
            "no of neuron= 15 Testing Accuracy: 0.351333\n",
            "no of neuron= 16 Testing Accuracy: 0.380778\n",
            "no of neuron= 17 Testing Accuracy: 0.416444\n",
            "no of neuron= 18 Testing Accuracy: 0.409111\n",
            "no of neuron= 19 Testing Accuracy: 0.383667\n",
            "no of neuron= 20 Testing Accuracy: 0.398667\n",
            "no of neuron= 21 Testing Accuracy: 0.463111\n",
            "no of neuron= 22 Testing Accuracy: 0.488222\n",
            "no of neuron= 23 Testing Accuracy: 0.442778\n",
            "no of neuron= 24 Testing Accuracy: 0.453778\n",
            "no of neuron= 25 Testing Accuracy: 0.447667\n",
            "no of neuron= 26 Testing Accuracy: 0.495556\n",
            "no of neuron= 27 Testing Accuracy: 0.509000\n",
            "no of neuron= 28 Testing Accuracy: 0.483889\n",
            "no of neuron= 29 Testing Accuracy: 0.482000\n",
            "no of neuron= 30 Testing Accuracy: 0.491111\n",
            "no of neuron= 31 Testing Accuracy: 0.484889\n",
            "no of neuron= 32 Testing Accuracy: 0.531778\n",
            "no of neuron= 33 Testing Accuracy: 0.525889\n",
            "no of neuron= 34 Testing Accuracy: 0.534667\n",
            "no of neuron= 35 Testing Accuracy: 0.539778\n",
            "no of neuron= 36 Testing Accuracy: 0.531556\n",
            "no of neuron= 37 Testing Accuracy: 0.568333\n",
            "no of neuron= 38 Testing Accuracy: 0.573556\n",
            "no of neuron= 39 Testing Accuracy: 0.591667\n",
            "no of neuron= 40 Testing Accuracy: 0.556111\n",
            "no of neuron= 41 Testing Accuracy: 0.597000\n",
            "no of neuron= 42 Testing Accuracy: 0.562556\n",
            "no of neuron= 43 Testing Accuracy: 0.603778\n",
            "no of neuron= 44 Testing Accuracy: 0.606667\n",
            "no of neuron= 45 Testing Accuracy: 0.586111\n",
            "no of neuron= 46 Testing Accuracy: 0.586667\n",
            "no of neuron= 47 Testing Accuracy: 0.603333\n",
            "no of neuron= 48 Testing Accuracy: 0.596333\n",
            "no of neuron= 49 Testing Accuracy: 0.616333\n",
            "no of neuron= 50 Testing Accuracy: 0.592556\n",
            "no of neuron= 51 Testing Accuracy: 0.617556\n",
            "no of neuron= 52 Testing Accuracy: 0.617778\n",
            "no of neuron= 53 Testing Accuracy: 0.627667\n",
            "no of neuron= 54 Testing Accuracy: 0.647667\n",
            "no of neuron= 55 Testing Accuracy: 0.620667\n",
            "no of neuron= 56 Testing Accuracy: 0.615111\n",
            "no of neuron= 57 Testing Accuracy: 0.653000\n",
            "no of neuron= 58 Testing Accuracy: 0.678111\n",
            "no of neuron= 59 Testing Accuracy: 0.614667\n",
            "no of neuron= 60 Testing Accuracy: 0.636667\n",
            "no of neuron= 61 Testing Accuracy: 0.644333\n",
            "no of neuron= 62 Testing Accuracy: 0.675111\n",
            "no of neuron= 63 Testing Accuracy: 0.674667\n",
            "no of neuron= 64 Testing Accuracy: 0.664222\n",
            "no of neuron= 65 Testing Accuracy: 0.646889\n",
            "no of neuron= 66 Testing Accuracy: 0.655667\n",
            "no of neuron= 67 Testing Accuracy: 0.669778\n",
            "no of neuron= 68 Testing Accuracy: 0.658000\n",
            "no of neuron= 69 Testing Accuracy: 0.675556\n",
            "no of neuron= 70 Testing Accuracy: 0.662889\n",
            "no of neuron= 71 Testing Accuracy: 0.680667\n",
            "no of neuron= 72 Testing Accuracy: 0.681333\n",
            "no of neuron= 73 Testing Accuracy: 0.690222\n",
            "no of neuron= 74 Testing Accuracy: 0.679333\n",
            "no of neuron= 75 Testing Accuracy: 0.716111\n",
            "no of neuron= 76 Testing Accuracy: 0.668444\n",
            "no of neuron= 77 Testing Accuracy: 0.680667\n",
            "no of neuron= 78 Testing Accuracy: 0.697222\n",
            "no of neuron= 79 Testing Accuracy: 0.694000\n",
            "no of neuron= 80 Testing Accuracy: 0.690889\n",
            "no of neuron= 81 Testing Accuracy: 0.695000\n",
            "no of neuron= 82 Testing Accuracy: 0.721889\n",
            "no of neuron= 83 Testing Accuracy: 0.700889\n",
            "no of neuron= 84 Testing Accuracy: 0.707889\n",
            "no of neuron= 85 Testing Accuracy: 0.713778\n",
            "no of neuron= 86 Testing Accuracy: 0.709444\n",
            "no of neuron= 87 Testing Accuracy: 0.711667\n",
            "no of neuron= 88 Testing Accuracy: 0.718444\n",
            "no of neuron= 89 Testing Accuracy: 0.715556\n",
            "no of neuron= 90 Testing Accuracy: 0.690889\n",
            "no of neuron= 91 Testing Accuracy: 0.733778\n",
            "no of neuron= 92 Testing Accuracy: 0.727556\n",
            "no of neuron= 93 Testing Accuracy: 0.715000\n",
            "no of neuron= 94 Testing Accuracy: 0.736222\n",
            "no of neuron= 95 Testing Accuracy: 0.725889\n",
            "no of neuron= 96 Testing Accuracy: 0.719778\n",
            "no of neuron= 97 Testing Accuracy: 0.744333\n",
            "no of neuron= 98 Testing Accuracy: 0.749889\n",
            "no of neuron= 99 Testing Accuracy: 0.729889\n",
            "no of neuron= 100 Testing Accuracy: 0.720000\n",
            "no of neuron= 101 Testing Accuracy: 0.746444\n",
            "no of neuron= 102 Testing Accuracy: 0.758222\n",
            "no of neuron= 103 Testing Accuracy: 0.734000\n",
            "no of neuron= 104 Testing Accuracy: 0.736778\n",
            "no of neuron= 105 Testing Accuracy: 0.757667\n",
            "no of neuron= 106 Testing Accuracy: 0.756333\n",
            "no of neuron= 107 Testing Accuracy: 0.748222\n",
            "no of neuron= 108 Testing Accuracy: 0.764333\n",
            "no of neuron= 109 Testing Accuracy: 0.756000\n",
            "no of neuron= 110 Testing Accuracy: 0.772333\n",
            "no of neuron= 111 Testing Accuracy: 0.772778\n",
            "no of neuron= 112 Testing Accuracy: 0.766778\n",
            "no of neuron= 113 Testing Accuracy: 0.776556\n",
            "no of neuron= 114 Testing Accuracy: 0.776556\n",
            "no of neuron= 115 Testing Accuracy: 0.768778\n",
            "no of neuron= 116 Testing Accuracy: 0.760111\n",
            "no of neuron= 117 Testing Accuracy: 0.765667\n",
            "no of neuron= 118 Testing Accuracy: 0.788111\n",
            "no of neuron= 119 Testing Accuracy: 0.762222\n",
            "no of neuron= 120 Testing Accuracy: 0.776778\n",
            "no of neuron= 121 Testing Accuracy: 0.780111\n",
            "no of neuron= 122 Testing Accuracy: 0.768444\n",
            "no of neuron= 123 Testing Accuracy: 0.780556\n",
            "no of neuron= 124 Testing Accuracy: 0.777111\n",
            "no of neuron= 125 Testing Accuracy: 0.791889\n",
            "no of neuron= 126 Testing Accuracy: 0.784333\n",
            "no of neuron= 127 Testing Accuracy: 0.790556\n",
            "no of neuron= 128 Testing Accuracy: 0.792889\n",
            "no of neuron= 129 Testing Accuracy: 0.775333\n",
            "no of neuron= 130 Testing Accuracy: 0.804111\n",
            "no of neuron= 131 Testing Accuracy: 0.782667\n",
            "no of neuron= 132 Testing Accuracy: 0.800222\n",
            "no of neuron= 133 Testing Accuracy: 0.790889\n",
            "no of neuron= 134 Testing Accuracy: 0.780111\n",
            "no of neuron= 135 Testing Accuracy: 0.799333\n",
            "no of neuron= 136 Testing Accuracy: 0.787778\n",
            "no of neuron= 137 Testing Accuracy: 0.790444\n",
            "no of neuron= 138 Testing Accuracy: 0.800889\n",
            "no of neuron= 139 Testing Accuracy: 0.793889\n",
            "no of neuron= 140 Testing Accuracy: 0.788333\n",
            "no of neuron= 141 Testing Accuracy: 0.806000\n",
            "no of neuron= 142 Testing Accuracy: 0.817333\n",
            "no of neuron= 143 Testing Accuracy: 0.804667\n",
            "no of neuron= 144 Testing Accuracy: 0.800111\n",
            "no of neuron= 145 Testing Accuracy: 0.794222\n",
            "no of neuron= 146 Testing Accuracy: 0.809111\n",
            "no of neuron= 147 Testing Accuracy: 0.798222\n",
            "no of neuron= 148 Testing Accuracy: 0.795111\n",
            "no of neuron= 149 Testing Accuracy: 0.811778\n",
            "no of neuron= 150 Testing Accuracy: 0.809778\n",
            "no of neuron= 151 Testing Accuracy: 0.809222\n",
            "no of neuron= 152 Testing Accuracy: 0.803778\n",
            "no of neuron= 153 Testing Accuracy: 0.812556\n",
            "no of neuron= 154 Testing Accuracy: 0.810778\n",
            "no of neuron= 155 Testing Accuracy: 0.797333\n",
            "no of neuron= 156 Testing Accuracy: 0.826556\n",
            "no of neuron= 157 Testing Accuracy: 0.816111\n",
            "no of neuron= 158 Testing Accuracy: 0.825667\n",
            "no of neuron= 159 Testing Accuracy: 0.819333\n",
            "no of neuron= 160 Testing Accuracy: 0.828000\n",
            "no of neuron= 161 Testing Accuracy: 0.808556\n",
            "no of neuron= 162 Testing Accuracy: 0.805222\n",
            "no of neuron= 163 Testing Accuracy: 0.821667\n",
            "no of neuron= 164 Testing Accuracy: 0.809333\n",
            "no of neuron= 165 Testing Accuracy: 0.818667\n",
            "no of neuron= 166 Testing Accuracy: 0.818667\n",
            "no of neuron= 167 Testing Accuracy: 0.831333\n",
            "no of neuron= 168 Testing Accuracy: 0.828111\n",
            "no of neuron= 169 Testing Accuracy: 0.827667\n",
            "no of neuron= 170 Testing Accuracy: 0.822111\n",
            "no of neuron= 171 Testing Accuracy: 0.829222\n",
            "no of neuron= 172 Testing Accuracy: 0.813778\n",
            "no of neuron= 173 Testing Accuracy: 0.820000\n",
            "no of neuron= 174 Testing Accuracy: 0.823000\n",
            "no of neuron= 175 Testing Accuracy: 0.809000\n",
            "no of neuron= 176 Testing Accuracy: 0.835778\n",
            "no of neuron= 177 Testing Accuracy: 0.836000\n",
            "no of neuron= 178 Testing Accuracy: 0.831889\n",
            "no of neuron= 179 Testing Accuracy: 0.835556\n",
            "no of neuron= 180 Testing Accuracy: 0.833222\n",
            "no of neuron= 181 Testing Accuracy: 0.824333\n",
            "no of neuron= 182 Testing Accuracy: 0.830111\n",
            "no of neuron= 183 Testing Accuracy: 0.840778\n",
            "no of neuron= 184 Testing Accuracy: 0.825667\n",
            "no of neuron= 185 Testing Accuracy: 0.829111\n",
            "no of neuron= 186 Testing Accuracy: 0.836444\n",
            "no of neuron= 187 Testing Accuracy: 0.833889\n",
            "no of neuron= 188 Testing Accuracy: 0.837111\n",
            "no of neuron= 189 Testing Accuracy: 0.855222\n",
            "no of neuron= 190 Testing Accuracy: 0.838444\n",
            "no of neuron= 191 Testing Accuracy: 0.845667\n",
            "no of neuron= 192 Testing Accuracy: 0.844222\n",
            "no of neuron= 193 Testing Accuracy: 0.838778\n",
            "no of neuron= 194 Testing Accuracy: 0.841000\n",
            "no of neuron= 195 Testing Accuracy: 0.851333\n",
            "no of neuron= 196 Testing Accuracy: 0.842111\n",
            "no of neuron= 197 Testing Accuracy: 0.839000\n",
            "no of neuron= 198 Testing Accuracy: 0.836111\n",
            "no of neuron= 199 Testing Accuracy: 0.848444\n",
            "no of neuron= 200 Testing Accuracy: 0.850000\n",
            "no of neuron= 201 Testing Accuracy: 0.844444\n",
            "no of neuron= 202 Testing Accuracy: 0.846111\n",
            "no of neuron= 203 Testing Accuracy: 0.841889\n",
            "no of neuron= 204 Testing Accuracy: 0.848222\n",
            "no of neuron= 205 Testing Accuracy: 0.841222\n",
            "no of neuron= 206 Testing Accuracy: 0.846889\n",
            "no of neuron= 207 Testing Accuracy: 0.858222\n",
            "no of neuron= 208 Testing Accuracy: 0.849111\n",
            "no of neuron= 209 Testing Accuracy: 0.848111\n",
            "no of neuron= 210 Testing Accuracy: 0.855667\n",
            "no of neuron= 211 Testing Accuracy: 0.847778\n",
            "no of neuron= 212 Testing Accuracy: 0.848778\n",
            "no of neuron= 213 Testing Accuracy: 0.845444\n",
            "no of neuron= 214 Testing Accuracy: 0.854000\n",
            "no of neuron= 215 Testing Accuracy: 0.857111\n",
            "no of neuron= 216 Testing Accuracy: 0.850333\n",
            "no of neuron= 217 Testing Accuracy: 0.853222\n",
            "no of neuron= 218 Testing Accuracy: 0.859222\n",
            "no of neuron= 219 Testing Accuracy: 0.858778\n",
            "no of neuron= 220 Testing Accuracy: 0.849667\n",
            "no of neuron= 221 Testing Accuracy: 0.850556\n",
            "no of neuron= 222 Testing Accuracy: 0.854444\n",
            "no of neuron= 223 Testing Accuracy: 0.853778\n",
            "no of neuron= 224 Testing Accuracy: 0.851000\n",
            "no of neuron= 225 Testing Accuracy: 0.860667\n",
            "no of neuron= 226 Testing Accuracy: 0.860111\n",
            "no of neuron= 227 Testing Accuracy: 0.867667\n",
            "no of neuron= 228 Testing Accuracy: 0.853000\n",
            "no of neuron= 229 Testing Accuracy: 0.883222\n",
            "no of neuron= 230 Testing Accuracy: 0.857111\n",
            "no of neuron= 231 Testing Accuracy: 0.851000\n",
            "no of neuron= 232 Testing Accuracy: 0.862444\n",
            "no of neuron= 233 Testing Accuracy: 0.869333\n",
            "no of neuron= 234 Testing Accuracy: 0.853556\n",
            "no of neuron= 235 Testing Accuracy: 0.857111\n",
            "no of neuron= 236 Testing Accuracy: 0.858111\n",
            "no of neuron= 237 Testing Accuracy: 0.866556\n",
            "no of neuron= 238 Testing Accuracy: 0.861667\n",
            "no of neuron= 239 Testing Accuracy: 0.859889\n",
            "no of neuron= 240 Testing Accuracy: 0.863333\n",
            "no of neuron= 241 Testing Accuracy: 0.864333\n",
            "no of neuron= 242 Testing Accuracy: 0.864111\n",
            "no of neuron= 243 Testing Accuracy: 0.863778\n",
            "no of neuron= 244 Testing Accuracy: 0.865111\n",
            "no of neuron= 245 Testing Accuracy: 0.872778\n",
            "no of neuron= 246 Testing Accuracy: 0.869556\n",
            "no of neuron= 247 Testing Accuracy: 0.873778\n",
            "no of neuron= 248 Testing Accuracy: 0.869889\n",
            "no of neuron= 249 Testing Accuracy: 0.862333\n",
            "no of neuron= 250 Testing Accuracy: 0.865444\n"
          ]
        }
      ],
      "source": [
        "Lmax=251\n",
        "input=x_training_features.size(1)\n",
        "ielm_model = I_ELM(\n",
        "no_input_nodes=input,\n",
        "max_no_hidden_nodes=Lmax,\n",
        "no_output_nodes=no_classes,\n",
        "loss_function=loss_function,\n",
        "activation_function=activation_function,    \n",
        ")\n",
        "activation='s'\n",
        "for i in range(Lmax):\n",
        "    ielm_model.fit(x_training_features,y_train_labels,i,error,activation)\n",
        "    testing_loss, testing_acc = ielm_model.evaluate(x_testing_features, y_testing_labels, metrics=['loss','accuracy'])\n",
        "    #print(\"neurons=\",i,'testing Loss in mean square error: %f ' % testing_loss,i) # loss value\n",
        "    print(\"no of neuron=\",i,'Testing Accuracy: %f' % testing_acc)# accuracy\n",
        "\n",
        "#print('testing Loss in mean square error: %f' % testing_loss) # loss value\n",
        "#print('Testing Accuracy: %f' % testing_acc)# accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Lmax=250\n",
        "activation='s'\n",
        "i_elm_model=i_elmTraining(x_training_features,y_train_labels,activation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i_elmTesting(i_elm_model,x_testing_features,y_testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Lmax=300\n",
        "activation='s'\n",
        "i_elm_model1=i_elmTraining(x_training_features,y_train_labels,activation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i_elmTesting(i_elm_model1,x_testing_features,y_testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Lmax=250\n",
        "activation='s'\n",
        "i_elm_model=i_elmTraining(x_training_features,y_train_labels,activation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i_elmTesting(i_elm_model,x_testing_features,y_testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Lmax=100\n",
        "activation='s'\n",
        "i_elm_model=i_elmTraining(x_training_features,y_train_labels,activation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i_elmTesting(i_elm_model,x_testing_features,y_testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Lmax=400\n",
        "activation='t'\n",
        "i_elm_model2=i_elmTraining(x_training_features,y_train_labels,activation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i_elmTesting(i_elm_model2,x_testing_features,y_testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Lmax=300\n",
        "activation='t'\n",
        "i_elm_model2=i_elmTraining(x_training_features,y_train_labels,activation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i_elmTesting(i_elm_model2,x_testing_features,y_testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Lmax=250\n",
        "activation='t'\n",
        "i_elm_model2=i_elmTraining(x_training_features,y_train_labels,activation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i_elmTesting(i_elm_model2,x_testing_features,y_testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Lmax = 100\n",
        "activation='t'\n",
        "i_elm_model2=i_elmTraining(x_training_features,y_train_labels,activation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i_elmTesting(i_elm_model2,x_testing_features,y_testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train_labels_reshaped=np.argmax(y_train_labels.detach().cpu().numpy(),axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_labels_reshaped=np.argmax(y_testing_labels.detach().cpu().numpy(),axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Initialize and train the naive bayes classifier\n",
        "naiveClassifier=GaussianNB(var_smoothing=1e-8)\n",
        "\n",
        "start_time=time.time()\n",
        "naiveClassifier.fit(x_training_features.cpu(),y_train_labels_reshaped)\n",
        "end_time=time.time()\n",
        "\n",
        "print(\"training_time =\", end_time-start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
        "testing_start_time=time.time()\n",
        "y_pred=naiveClassifier.predict(x_testing_features.cpu())\n",
        "testing_stop_time=time.time()\n",
        "print(\"testing time=\", testing_stop_time-testing_start_time)\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test_labels_reshaped,y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "precision_1 = precision_score(y_test_labels_reshaped, y_pred,average='macro')\n",
        "recall=recall_score(y_test_labels_reshaped, y_pred,average='macro')\n",
        "fscore=f1_score(y_test_labels_reshaped, y_pred,average='macro')\n",
        "print(\"precision:\",precision_1)\n",
        "print(\"recall\",recall)\n",
        "print(\"f1-Score\",fscore)\n",
        "cm = confusion_matrix(y_test_labels_reshaped, y_pred)\n",
        "\n",
        "# Extract true positives (TP), false positives (FP), false negatives (FN), and true negatives (TN) from the confusion matrix\n",
        "tp = cm[1, 1]\n",
        "fp = cm[0, 1]\n",
        "fn = cm[1, 0]\n",
        "tn = cm[0, 0]\n",
        "\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"sensivity=\",sensitivity)\n",
        "TPR= tp/(tp+fn)\n",
        "FPR=fp/(fp+tn)\n",
        "X=[0,FPR,1]\n",
        "Y=[0,TPR,1]\n",
        "AUCSCORE =np.trapz(Y,X)\n",
        "print(\"AUCSCORE=\", AUCSCORE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "import time\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "svm=SVC(C=1,kernel='linear',gamma='auto')\n",
        "\n",
        "start_time= time.time()\n",
        "#svm=svm.cuda().to(device)\n",
        "svm.fit(x_training_features.cpu(),y_train_labels_reshaped)\n",
        "end_time=time.time()\n",
        "print(\"training time=\",end_time-start_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
        "testing_start_time=time.time()\n",
        "y_pred=svm.predict(x_testing_features.cpu())\n",
        "testing_stop_time=time.time()\n",
        "print(\"testing time=\", testing_stop_time-testing_start_time)\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test_labels_reshaped,y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "precision_1 = precision_score(y_test_labels_reshaped, y_pred,average='macro')\n",
        "recall=recall_score(y_test_labels_reshaped, y_pred,average='macro')\n",
        "fscore=f1_score(y_test_labels_reshaped, y_pred,average='macro')\n",
        "print(\"precision:\",precision_1)\n",
        "print(\"recall\",recall)\n",
        "print(\"f1-Score\",fscore)\n",
        "cm = confusion_matrix(y_test_labels_reshaped, y_pred)\n",
        "\n",
        "# Extract true positives (TP), false positives (FP), false negatives (FN), and true negatives (TN) from the confusion matrix\n",
        "tp = cm[1, 1]\n",
        "fp = cm[0, 1]\n",
        "fn = cm[1, 0]\n",
        "tn = cm[0, 0]\n",
        "\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "print(\"Specificity:\", specificity,\"sensivity=\",sensitivity)\n",
        "\n",
        "TPR= tp/(tp+fn)\n",
        "FPR=fp/(fp+tn)\n",
        "X=[0,FPR,1]\n",
        "Y=[0,TPR,1]\n",
        "AUCSCORE =np.trapz(Y,X)\n",
        "print(\"AUCSCORE=\", AUCSCORE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Random Forest classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import time\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
        "start_time= time.time()\n",
        "rf_classifier.fit(x_training_features.cpu(),y_train_labels_reshaped)\n",
        "end_time=time.time()\n",
        "print(\"training time=\",end_time-start_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on the testing set\n",
        "from sklearn.metrics import accuracy_score\n",
        "testing_start_time=time.time()\n",
        "y_pred = rf_classifier.predict(x_testing_features.cpu())\n",
        "testing_stop_time=time.time()\n",
        "print(\"testing time=\", testing_stop_time-testing_start_time)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test_labels_reshaped, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "from sklearn.metrics import precision_score,recall_score,f1_score\n",
        "precision_1 = precision_score(y_test_labels_reshaped, y_pred,average='macro')\n",
        "recall=recall_score(y_test_labels_reshaped, y_pred,average='macro')\n",
        "fscore=f1_score(y_test_labels_reshaped, y_pred,average='macro')\n",
        "\n",
        "cm = confusion_matrix(y_test_labels_reshaped, y_pred)\n",
        "# Extract true positives (TP), false positives (FP), false negatives (FN), and true negatives (TN) from the confusion matrix\n",
        "tp = cm[1, 1]\n",
        "fp = cm[0, 1]\n",
        "fn = cm[1, 0]\n",
        "tn = cm[0, 0]\n",
        "#print(tp,fp)\n",
        "\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "print(\"precision:\",precision_1)\n",
        "print(\"recall\",recall)\n",
        "print(\"f1-Score\",fscore)\n",
        "\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"sensivity=\",sensitivity)\n",
        "TPR= tp/(tp+fn)\n",
        "FPR=fp/(fp+tn)\n",
        "X=[0,FPR,1]\n",
        "Y=[0,TPR,1]\n",
        "AUCSCORE =np.trapz(Y,X)\n",
        "print(\"AUCSCORE=\", AUCSCORE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Decision tree classifier    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# Create a Decision Tree classifier\n",
        "dt_classifier = DecisionTreeClassifier(criterion='gini')\n",
        "\n",
        "start_time= time.time()\n",
        "dt_classifier.fit(x_training_features.cpu(),y_train_labels_reshaped)\n",
        "end_time=time.time()\n",
        "print(\"training time=\",end_time-start_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Make predictions on the testing set\n",
        "from sklearn.metrics import accuracy_score\n",
        "testing_start_time=time.time()\n",
        "y_pred = dt_classifier.predict(x_testing_features.cpu())\n",
        "testing_stop_time=time.time()\n",
        "print(\"testing time=\", testing_stop_time-testing_start_time)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test_labels_reshaped,y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "from sklearn.metrics import precision_score,recall_score,f1_score\n",
        "precision_1 = precision_score(y_test_labels_reshaped,y_pred,average='macro')\n",
        "recall=recall_score(y_test_labels_reshaped,y_pred,average='macro')\n",
        "fscore=f1_score(y_test_labels_reshaped,y_pred,average='macro')\n",
        "print(\"precision:\",precision_1)\n",
        "print(\"recall\",recall)\n",
        "print(\"f1-Score\",fscore)\n",
        "\n",
        "cm = confusion_matrix(y_test_labels_reshaped,y_pred)\n",
        "#print(cm)\n",
        "# Extract true positives (TP), false positives (FP), false negatives (FN), and true negatives (TN) from the confusion matrix\n",
        "tp = cm[1, 1]\n",
        "fp = cm[0, 1]\n",
        "fn = cm[1, 0]\n",
        "tn = cm[0, 0]\n",
        "#print(tp,fp)\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"sensivity=\",sensitivity)\n",
        "TPR= tp/(tp+fn)\n",
        "FPR=fp/(fp+tn)\n",
        "X=[0,FPR,1]\n",
        "Y=[0,TPR,1]\n",
        "AUCSCORE =np.trapz(Y,X)\n",
        "print(\"AUCSCORE=\", AUCSCORE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ET Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
        "\n",
        "# Create the Extra Trees classifier\n",
        "clf = ExtraTreesClassifier(criterion=\"gini\")\n",
        "\n",
        "start_time=time.time()\n",
        "clf.fit(x_training_features.cpu(), y_train_labels_reshaped)\n",
        "#model.fit(, )\n",
        "stop_time=time.time()\n",
        "print(\"trainingtime=\",stop_time-start_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "testing_start_time=time.time()\n",
        "y_pred = clf.predict(x_testing_features.cpu())\n",
        "testing_stop_time=time.time()\n",
        "print(\"testing time =\", testing_stop_time-testing_start_time)\n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy = accuracy_score(y_test_labels_reshaped, y_pred)\n",
        "\n",
        "print(\"accuracy:\",accuracy)\n",
        "from sklearn.metrics import precision_score,recall_score,f1_score\n",
        "precision_1 = precision_score(y_test_labels_reshaped,y_pred,average='macro')\n",
        "recall=recall_score(y_test_labels_reshaped,y_pred,average='macro')\n",
        "fscore=f1_score(y_test_labels_reshaped,y_pred,average='macro')\n",
        "print(\"precision:\",precision_1)\n",
        "print(\"recall\",recall)\n",
        "print(\"f1-Score\",fscore)\n",
        "\n",
        "cm = confusion_matrix(y_test_labels_reshaped,y_pred)\n",
        "#print(cm)\n",
        "# Extract true positives (TP), false positives (FP), false negatives (FN), and true negatives (TN) from the confusion matrix\n",
        "tp = cm[1, 1]\n",
        "fp = cm[0, 1]\n",
        "fn = cm[1, 0]\n",
        "tn = cm[0, 0]\n",
        "#print(tp,fp)\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"sensivity=\",sensitivity)\n",
        "TPR= tp/(tp+fn)\n",
        "FPR=fp/(fp+tn)\n",
        "X=[0,FPR,1]\n",
        "Y=[0,TPR,1]\n",
        "AUCSCORE =np.trapz(Y,X)\n",
        "print(\"AUCSCORE=\", AUCSCORE)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
        "\n",
        "# Create the Extra Trees classifier\n",
        "clf1 = ExtraTreesClassifier(criterion=\"entropy\")\n",
        "\n",
        "start_time=time.time()\n",
        "clf1.fit(x_training_features.cpu(), y_train_labels_reshaped)\n",
        "#model.fit(, )\n",
        "stop_time=time.time()\n",
        "print(\"trainingtime=\",stop_time-start_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "testing_start_time=time.time()\n",
        "y_pred = clf1.predict(x_testing_features.cpu())\n",
        "testing_stop_time=time.time()\n",
        "print(\"testing time =\", testing_stop_time-testing_start_time)\n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy = accuracy_score(y_test_labels_reshaped, y_pred)\n",
        "\n",
        "print(\"accuracy:\",accuracy)\n",
        "from sklearn.metrics import precision_score,recall_score,f1_score\n",
        "fscore=f1_score(y_test_labels_reshaped, y_pred,average='macro')\n",
        "print(\"precision:\",precision_1)\n",
        "print(\"recall\",recall)\n",
        "print(\"f1-Score\",fscore)\n",
        "\n",
        "\n",
        "# Assuming y_true and y_pred are your true and predicted labels, respectively\n",
        "# Assuming y_true and y_pred are your true and predicted labels, respectively\n",
        "cm = confusion_matrix(y_test_labels_reshaped, y_pred)\n",
        "#print(cm)\n",
        "# Extract true positives (TP), false positives (FP), false negatives (FN), and true negatives (TN) from the confusion matrix\n",
        "tp = cm[1, 1]\n",
        "fp = cm[0, 1]\n",
        "fn = cm[1, 0]\n",
        "tn = cm[0, 0]\n",
        "#print(tp,fp)\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"sensivity=\",sensitivity)\n",
        "TPR= tp/(tp+fn)\n",
        "FPR=fp/(fp+tn)\n",
        "X=[0,FPR,1]\n",
        "Y=[0,TPR,1]\n",
        "AUCSCORE =np.trapz(Y,X)\n",
        "print(\"AUCSCORE=\", AUCSCORE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "model = xgb.XGBClassifier(\n",
        "    n_estimators=100,  # Number of boosting rounds\n",
        "    max_depth=3,  # Maximum depth of each tree\n",
        "    learning_rate=0.001,  # Learning rate (step size shrinkage)\n",
        "    objective='multi:softprob',  # Objective function for binary classification\n",
        "    random_state=42,n_jobs=4,booster =\"gbtree\", gamma = 0\n",
        ")\n",
        "start_time=time.time()\n",
        "model.fit(x_training_features.cpu(), y_train_labels_reshaped)\n",
        "stop_time=time.time()\n",
        "print(\"trainingtime=\",stop_time-start_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "testing_start_time=time.time()\n",
        "y_pred = model.predict(x_testing_features.cpu())\n",
        "testing_stop_time=time.time()\n",
        "print(\"testing time =\", testing_stop_time-testing_start_time)\n",
        "report = classification_report(y_test_labels_reshaped, y_pred)\n",
        "print(report)\n",
        "# Calculate accuracy score\n",
        "accuracy = accuracy_score(y_test_labels_reshaped, y_pred)\n",
        "\n",
        "print(\"accuracy:\",accuracy)\n",
        "from sklearn.metrics import precision_score,recall_score,f1_score\n",
        "precision_1 = precision_score(y_test_labels_reshaped, y_pred,average='macro')\n",
        "recall=recall_score(y_test_labels_reshaped, y_pred,average='macro')\n",
        "fscore=f1_score(y_test_labels_reshaped, y_pred,average='macro')\n",
        "print(\"precision:\",precision_1)\n",
        "print(\"recall\",recall)\n",
        "print(\"f1-Score\",fscore)\n",
        "\n",
        "\n",
        "# Assuming y_true and y_pred are your true and predicted labels, respectively\n",
        "# Assuming y_true and y_pred are your true and predicted labels, respectively\n",
        "cm = confusion_matrix(y_test_labels_reshaped, y_pred)\n",
        "print(cm)\n",
        "# Extract true positives (TP), false positives (FP), false negatives (FN), and true negatives (TN) from the confusion matrix\n",
        "tp = cm[1, 1]\n",
        "fp = cm[0, 1]\n",
        "fn = cm[1, 0]\n",
        "tn = cm[0, 0]\n",
        "#print(tp,fp)\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "print(\"Specificity:\", specificity,\"sensivity=\",sensitivity)\n",
        "TPR= tp/(tp+fn)\n",
        "FPR=fp/(fp+tn)\n",
        "X=[0,FPR,1]\n",
        "Y=[0,FPR,1]\n",
        "AUCSCORE =np.trapz(Y,X)\n",
        "print(\"AUCSCORE=\", AUCSCORE)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
